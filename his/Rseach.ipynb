{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2265b831-aca5-4125-bfde-c5ba761924fc",
   "metadata": {},
   "source": [
    "## Load Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6615358-7618-4990-85a7-51adc255ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_student gender                region      highest_education imd_band  \\\n",
      "0       11391      M   East Anglian Region       HE Qualification  90-100%   \n",
      "1       28400      F              Scotland       HE Qualification   20-30%   \n",
      "2       31604      F     South East Region  A Level or Equivalent   50-60%   \n",
      "3       32885      F  West Midlands Region     Lower Than A Level   50-60%   \n",
      "4       38053      M                 Wales  A Level or Equivalent   80-90%   \n",
      "\n",
      "  age_band  num_of_prev_attempts  studied_credits disability final_result  \\\n",
      "0     55<=                     0              240          N         Pass   \n",
      "1    35-55                     0               60          N         Pass   \n",
      "2    35-55                     0               60          N         Pass   \n",
      "3     0-35                     0               60          N         Pass   \n",
      "4    35-55                     0               60          N         Pass   \n",
      "\n",
      "   id_assessment assessment_type  assessment_date  assessment_weight  \\\n",
      "0           1752             TMA             19.0               10.0   \n",
      "1           1752             TMA             19.0               10.0   \n",
      "2           1752             TMA             19.0               10.0   \n",
      "3           1752             TMA             19.0               10.0   \n",
      "4           1752             TMA             19.0               10.0   \n",
      "\n",
      "  code_module code_presentation  module_presentation_length  score  \n",
      "0         AAA             2013J                         268   78.0  \n",
      "1         AAA             2013J                         268   70.0  \n",
      "2         AAA             2013J                         268   72.0  \n",
      "3         AAA             2013J                         268   69.0  \n",
      "4         AAA             2013J                         268   79.0  \n",
      "Index(['id_student', 'gender', 'region', 'highest_education', 'imd_band',\n",
      "       'age_band', 'num_of_prev_attempts', 'studied_credits', 'disability',\n",
      "       'final_result', 'id_assessment', 'assessment_type', 'assessment_date',\n",
      "       'assessment_weight', 'code_module', 'code_presentation',\n",
      "       'module_presentation_length', 'score'],\n",
      "      dtype='object')\n",
      "Column 'your_actual_category_column_name' does not exist in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_file.csv' with the actual file path)\n",
    "data = pd.read_csv('fine_data_set-elt.csv')\n",
    "\n",
    "# Check the first few rows and the columns of the dataset\n",
    "print(data.head())\n",
    "print(data.columns)  # This will print out all the column names in your DataFrame\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "data['score'] = data['score'].fillna(data['score'].mean())\n",
    "\n",
    "# If 'assessment_date' is a numerical column, this is fine; if it's a date, handle it differently\n",
    "data['assessment_date'] = data['assessment_date'].fillna(data['assessment_date'].mean())\n",
    "\n",
    "# Check if 'category_column' exists before filling missing values\n",
    "category_column_name = 'your_actual_category_column_name'  # Replace this with the correct name\n",
    "if category_column_name in data.columns:\n",
    "    data[category_column_name] = data[category_column_name].fillna(data[category_column_name].mode()[0])\n",
    "else:\n",
    "    print(f\"Column '{category_column_name}' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f213810-15ae-4175-bdf4-0059c1a6ced0",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306b6be3-3d49-4937-93e9-e07e81ff7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.52      0.50      5869\n",
      "           1       0.39      0.41      0.40      6529\n",
      "           2       0.69      0.68      0.69     22409\n",
      "           3       0.37      0.38      0.38      5036\n",
      "\n",
      "    accuracy                           0.57     39843\n",
      "   macro avg       0.49      0.49      0.49     39843\n",
      "weighted avg       0.58      0.57      0.57     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_file.csv' with the actual file path)\n",
    "data = pd.read_csv('fine_data_set-elt.csv')\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "data['score'] = data['score'].fillna(data['score'].mean())\n",
    "data['assessment_date'] = data['assessment_date'].fillna(data['assessment_date'].mean())\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "data['imd_band'] = data['imd_band'].fillna(data['imd_band'].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'final_result', 'assessment_type', 'code_module', 'code_presentation']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('final_result', axis=1)\n",
    "y = data['final_result']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbd402-7bcf-427d-b938-cf484890b615",
   "metadata": {},
   "source": [
    "# Radndom Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4061e0-854b-4b88-91aa-037720e2a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.52      0.50      5869\n",
      "           1       0.39      0.41      0.40      6529\n",
      "           2       0.69      0.68      0.69     22409\n",
      "           3       0.37      0.38      0.38      5036\n",
      "\n",
      "    accuracy                           0.57     39843\n",
      "   macro avg       0.49      0.49      0.49     39843\n",
      "weighted avg       0.58      0.57      0.57     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "random_forest = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "accuracy_rf, report_rf\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82e1bd-7adf-49aa-8ae5-4f69396db3b8",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e190940c-bd60-45eb-8840-2028ad930dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.41\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.69      0.43      5869\n",
      "           1       0.33      0.43      0.37      6529\n",
      "           2       0.73      0.32      0.44     22409\n",
      "           3       0.27      0.44      0.33      5036\n",
      "\n",
      "    accuracy                           0.41     39843\n",
      "   macro avg       0.41      0.47      0.39     39843\n",
      "weighted avg       0.54      0.41      0.41     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('fine_data_set-elt.csv')\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "data['score'] = data['score'].fillna(data['score'].mean())\n",
    "data['assessment_date'] = data['assessment_date'].fillna(data['assessment_date'].mean())\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "data['imd_band'] = data['imd_band'].fillna(data['imd_band'].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'final_result', 'assessment_type', 'code_module', 'code_presentation']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('final_result', axis=1)\n",
    "y = data['final_result']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression Classifier with increased max_iter and balanced class weights\n",
    "logistic_regression = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736d9d2-3eba-4863-bc15-36d171fcdfdf",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1580cb-fefd-4c2b-aee3-88420584d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.68\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58      5869\n",
      "           1       0.61      0.39      0.48      6529\n",
      "           2       0.70      0.87      0.78     22409\n",
      "           3       0.55      0.38      0.45      5036\n",
      "\n",
      "    accuracy                           0.68     39843\n",
      "   macro avg       0.64      0.54      0.57     39843\n",
      "weighted avg       0.67      0.68      0.66     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da28520d-3c87-4aef-b77b-9af84d598405",
   "metadata": {},
   "source": [
    "# Support Vecotr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53a0e95-35d0-4b7f-8a42-f1ce36807d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.61\n",
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.13      0.22      5869\n",
      "           1       0.60      0.17      0.26      6529\n",
      "           2       0.61      0.97      0.75     22409\n",
      "           3       0.62      0.14      0.23      5036\n",
      "\n",
      "    accuracy                           0.61     39843\n",
      "   macro avg       0.64      0.35      0.36     39843\n",
      "weighted avg       0.63      0.61      0.52     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a Support Vector Classifier\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "print(f\"SVC Accuracy: {accuracy:.2f}\")\n",
    "print(\"SVC Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cf22f-155f-4c38-957a-bd8c42c01bb6",
   "metadata": {},
   "source": [
    "# Logistc regrstion , Support Vector,  Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba7a8ea4-a17e-4380-a491-1b05e71dc42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.56\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5869\n",
      "           1       0.28      0.00      0.00      6529\n",
      "           2       0.57      0.98      0.72     22409\n",
      "           3       0.35      0.07      0.12      5036\n",
      "\n",
      "    accuracy                           0.56     39843\n",
      "   macro avg       0.30      0.26      0.21     39843\n",
      "weighted avg       0.41      0.56      0.42     39843\n",
      "\n",
      "Random Forest Accuracy: 0.68\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58      5869\n",
      "           1       0.61      0.39      0.48      6529\n",
      "           2       0.70      0.87      0.78     22409\n",
      "           3       0.55      0.38      0.45      5036\n",
      "\n",
      "    accuracy                           0.68     39843\n",
      "   macro avg       0.64      0.54      0.57     39843\n",
      "weighted avg       0.67      0.68      0.66     39843\n",
      "\n",
      "SVC Accuracy: 0.56\n",
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5869\n",
      "           1       0.00      0.00      0.00      6529\n",
      "           2       0.56      1.00      0.72     22409\n",
      "           3       0.00      0.00      0.00      5036\n",
      "\n",
      "    accuracy                           0.56     39843\n",
      "   macro avg       0.14      0.25      0.18     39843\n",
      "weighted avg       0.32      0.56      0.40     39843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mit/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('fine_data_set-elt.csv')\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "data['score'] = data['score'].fillna(data['score'].mean())\n",
    "data['assessment_date'] = data['assessment_date'].fillna(data['assessment_date'].mean())\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "data['imd_band'] = data['imd_band'].fillna(data['imd_band'].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'final_result', 'assessment_type', 'code_module', 'code_presentation']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('final_result', axis=1)\n",
    "y = data['final_result']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(f\"SVC Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"SVC Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517e0a2-d248-44c6-9fcb-59d9b6ebcd38",
   "metadata": {},
   "source": [
    "# K-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ff801f-20d5-4a82-8197-ec16ecd62c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.75\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      5869\n",
      "           1       0.67      0.60      0.64      6529\n",
      "           2       0.81      0.86      0.83     22409\n",
      "           3       0.57      0.44      0.50      5036\n",
      "\n",
      "    accuracy                           0.75     39843\n",
      "   macro avg       0.69      0.66      0.67     39843\n",
      "weighted avg       0.74      0.75      0.74     39843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_file.csv' with the actual file path)\n",
    "data = pd.read_csv('fine_data_set-elt.csv')\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "data['score'] = data['score'].fillna(data['score'].mean())\n",
    "data['assessment_date'] = data['assessment_date'].fillna(data['assessment_date'].mean())\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "data['imd_band'] = data['imd_band'].fillna(data['imd_band'].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'final_result', 'assessment_type', 'code_module', 'code_presentation']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('final_result', axis=1)\n",
    "y = data['final_result']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a K-Nearest Neighbors Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can change n_neighbors as needed\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Display accuracy and classification report\n",
    "print(f\"KNN Accuracy: {accuracy:.2f}\")\n",
    "print(\"KNN Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e86fb-9379-4c7c-9db9-d7df93b02855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
