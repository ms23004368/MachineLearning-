{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8224ffa",
   "metadata": {},
   "source": [
    "# Implementation of Random Forest, Logistic Regression, K-Means, DBSCAN, and Q-Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100492f3",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates the code for implementing five popular machine learning algorithms:\n",
    "1. Random Forest\n",
    "2. Logistic Regression\n",
    "3. K-Means Clustering\n",
    "4. DBSCAN Clustering\n",
    "5. Q-Learning\n",
    "\n",
    "Each section includes code and brief explanations to understand the implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3118b3d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Random Forest Classifier\n",
    "\n",
    "Random Forest is an ensemble algorithm that builds multiple decision trees and combines them for improved accuracy and reduced overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `X` and `y` are the feature matrix and target vector\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76cb1c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear model for binary classification that predicts the probability of a target variable belonging to a particular class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44810bef",
   "metadata": {},
   "source": [
    "\n",
    "## 3. K-Means Clustering\n",
    "\n",
    "K-Means is an unsupervised clustering algorithm that groups data points into a specified number of clusters based on similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize and fit K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Plotting the Clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis', marker='o', edgecolor='k')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='x')\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961a722",
   "metadata": {},
   "source": [
    "\n",
    "## 4. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "\n",
    "DBSCAN is a density-based clustering algorithm that groups points in high-density areas and identifies noise points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize and fit DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Plotting DBSCAN results\n",
    "plt.scatter(X[:, 0], X[:, 1], c=dbscan.labels_, cmap='plasma', marker='o', edgecolor='k')\n",
    "plt.title(\"DBSCAN Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204277e0",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Q-Learning\n",
    "\n",
    "Q-Learning is a reinforcement learning algorithm that trains an agent to learn the optimal policy by maximizing cumulative reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize parameters\n",
    "state_space = 5  # Example: 5 states\n",
    "action_space = 3  # Example: 3 actions\n",
    "Q_table = np.zeros((state_space, action_space))\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 0.2  # Exploration rate\n",
    "\n",
    "# Define a function to choose an action (epsilon-greedy policy)\n",
    "def choose_action(state):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return np.random.choice(action_space)  # Explore\n",
    "    else:\n",
    "        return np.argmax(Q_table[state, :])  # Exploit\n",
    "\n",
    "# Training Loop\n",
    "episodes = 1000\n",
    "for _ in range(episodes):\n",
    "    state = np.random.randint(0, state_space)  # Random initial state\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = choose_action(state)\n",
    "        # Take action and observe reward and next state (example values)\n",
    "        next_state = (state + action) % state_space\n",
    "        reward = np.random.randn()  # Random reward\n",
    "        done = np.random.rand() > 0.95  # Random termination condition\n",
    "        \n",
    "        # Update Q-value\n",
    "        Q_table[state, action] = Q_table[state, action] + alpha * (reward + gamma * np.max(Q_table[next_state, :]) - Q_table[state, action])\n",
    "        state = next_state  # Move to the next state\n",
    "\n",
    "print(\"Trained Q-Table:\")\n",
    "print(Q_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
